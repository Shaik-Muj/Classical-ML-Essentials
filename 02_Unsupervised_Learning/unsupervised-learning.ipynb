{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Unsupervised Learning**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"#### Imports\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:03:02.381951Z","iopub.execute_input":"2025-10-20T13:03:02.382660Z","iopub.status.idle":"2025-10-20T13:03:02.387909Z","shell.execute_reply.started":"2025-10-20T13:03:02.382629Z","shell.execute_reply":"2025-10-20T13:03:02.386745Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Data Loading\n","metadata":{}},{"cell_type":"code","source":"sns.set_style(\"whitegrid\")\n\ndata = load_breast_cancer(as_frame = True)\nX = data.data\ny = data.target\n\nprint(f\"Data Loaded. Number of features are - {X.shape[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:03:06.040250Z","iopub.execute_input":"2025-10-20T13:03:06.040552Z","iopub.status.idle":"2025-10-20T13:03:06.061481Z","shell.execute_reply.started":"2025-10-20T13:03:06.040528Z","shell.execute_reply":"2025-10-20T13:03:06.060604Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Feature Scaling","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42, test_size=0.2)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\nprint(\"Data successfully scaled\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:03:08.477730Z","iopub.execute_input":"2025-10-20T13:03:08.478050Z","iopub.status.idle":"2025-10-20T13:03:08.490670Z","shell.execute_reply.started":"2025-10-20T13:03:08.478029Z","shell.execute_reply":"2025-10-20T13:03:08.489863Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Principal Component Analysis (PCA) and Explained Variance","metadata":{}},{"cell_type":"code","source":"pca = PCA()\npca.fit(X_train_scaled)\n\n# Analyze Explained Variance (Scree Plot)\nexplained_variance_ratio = pca.explained_variance_ratio_\n\nplt.figure(figsize=(10, 5))\nplt.plot(np.cumsum(explained_variance_ratio), marker='o', linestyle='--')\nplt.title('Cumulative Explained Variance by PCA Components (Scree Plot)')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.axhline(y=0.95, color='r', linestyle='-', label='95% Variance Threshold')\nplt.grid(True)\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:03:10.846161Z","iopub.execute_input":"2025-10-20T13:03:10.846968Z","iopub.status.idle":"2025-10-20T13:03:11.192241Z","shell.execute_reply.started":"2025-10-20T13:03:10.846928Z","shell.execute_reply":"2025-10-20T13:03:11.191122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_components_95 = np.argmax(np.cumsum(explained_variance_ratio) >= 0.95) + 1\nprint(f\"Original features count: {X_train_scaled.shape[1]}\")\nprint(f\"Number of components needed to retain 95% of variance: {n_components_95}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:07:46.081246Z","iopub.execute_input":"2025-10-20T13:07:46.081661Z","iopub.status.idle":"2025-10-20T13:07:46.087889Z","shell.execute_reply.started":"2025-10-20T13:07:46.081631Z","shell.execute_reply":"2025-10-20T13:07:46.086764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca_final = PCA(n_components=n_components_95)\nX_train_pca = pca_final.fit_transform(X_train_scaled)\n\nprint(f\"Reduced features count: {X_train_pca.shape[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:07:56.891695Z","iopub.execute_input":"2025-10-20T13:07:56.892386Z","iopub.status.idle":"2025-10-20T13:07:56.904742Z","shell.execute_reply.started":"2025-10-20T13:07:56.892354Z","shell.execute_reply":"2025-10-20T13:07:56.903865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### K-Means - Finding Optimal K","metadata":{}},{"cell_type":"code","source":"wcss = []\nk_range = range(1,11)\n\nfor k in k_range :\n    kmeans = KMeans(\n        n_clusters=k,\n        init='k-means++',\n        max_iter=300,\n        n_init=10,\n        random_state=42\n    )\n    kmeans.fit(X_train_pca)\n    wcss.append(kmeans.inertia_)\n\nplt.figure(figsize=(10, 5))\nplt.plot(k_range, wcss, marker='o', linestyle='-')\nplt.title('Elbow Method for Optimal K')\nplt.xlabel('Number of Clusters (K)')\nplt.ylabel('WCSS / Inertia')\nplt.xticks(k_range)\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:54:58.983384Z","iopub.execute_input":"2025-10-20T13:54:58.983749Z","iopub.status.idle":"2025-10-20T13:54:59.618980Z","shell.execute_reply.started":"2025-10-20T13:54:58.983726Z","shell.execute_reply":"2025-10-20T13:54:59.617895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimal_k = 2 \nprint(f\"Selected optimal K = {optimal_k} based on the elbow method interpretation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:55:23.898395Z","iopub.execute_input":"2025-10-20T13:55:23.898900Z","iopub.status.idle":"2025-10-20T13:55:23.905876Z","shell.execute_reply.started":"2025-10-20T13:55:23.898835Z","shell.execute_reply":"2025-10-20T13:55:23.904540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final K-Means Model and Visualization ###\n\n# 1. Run K-Means with the chosen optimal K\nkmeans_final = KMeans(\n    n_clusters=optimal_k, \n    init='k-means++', \n    n_init=10, \n    random_state=42\n)\nclusters = kmeans_final.fit_predict(X_train_pca)\n\n# 2. Prepare data for visualization (using the first two components)\nX_pca_df = pd.DataFrame(X_train_pca)\nX_pca_df['Cluster'] = clusters\n\n# 3. Visualize the Clusters\nplt.figure(figsize=(10, 7))\nsns.scatterplot(\n    x=0, # Principal Component 1\n    y=1, # Principal Component 2\n    hue='Cluster', \n    data=X_pca_df, \n    palette='Set1', \n    s=100, \n    alpha=0.7\n)\n\n# Plot the cluster centroids\nplt.scatter(\n    kmeans_final.cluster_centers_[:, 0], \n    kmeans_final.cluster_centers_[:, 1], \n    marker='X', \n    s=250, \n    color='black', \n    label='Centroids'\n)\n\nplt.title(f'K-Means Clustering (K={optimal_k}) on First Two PCA Components')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:02:04.484964Z","iopub.execute_input":"2025-10-20T14:02:04.485379Z","iopub.status.idle":"2025-10-20T14:02:04.990445Z","shell.execute_reply.started":"2025-10-20T14:02:04.485355Z","shell.execute_reply":"2025-10-20T14:02:04.989441Z"}},"outputs":[],"execution_count":null}]}